{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "it_news_title_category.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "64lb59mPm_lR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RM-eg0dEiao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Flatten, Concatenate, Input, LSTM\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydbQv_xFFQQN",
        "colab_type": "text"
      },
      "source": [
        "# 데이터 로드 및 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecXGLAUTHMEQ",
        "colab_type": "text"
      },
      "source": [
        "# 뉴스 카테고리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7LgP7bOgmcX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# json 읽어오기\n",
        "# news_data = pd.read_json('/content/drive/My Drive/News_Category_Dataset_v2.json', lines=True)\n",
        "# print(news_data)\n",
        "news_data = pd.read_csv('/content/drive/My Drive/ITchosun_content.csv')\n",
        "\n",
        "news_data = news_data.loc[:, [\"title\", \"tag\",\"small_category\"]]\n",
        "news_data=news_data.rename(columns={\"small_category\":'category'})\n",
        "# print(news_data)\n",
        "news_data=news_data.dropna(axis=0)\n",
        "news_data.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jreTt_Uijkq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt_pnlx5r7W5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 카테고리 정수 인코딩\n",
        "# news_data['category'] = news_data['category'].replace(~~~~~~~, ~~~~~)\n",
        "# print(pd.factorize(news_data['category']))\n",
        "category_list = pd.factorize(news_data['category'])[1]\n",
        "news_data['category'] = pd.factorize(news_data['category'])[0]\n",
        "\n",
        "news_data['category'].nunique()\n",
        "# category_list.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJwlYft7jow2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drop1=news_data[news_data['category'] == 24].index\n",
        "news_data=news_data.drop(drop1)\n",
        "drop2=news_data[news_data['category'] == 25].index\n",
        "news_data=news_data.drop(drop2)\n",
        "news_data.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E76PAokcnx0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "news_data.category.unique() # --> 26가지의 카테고리"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y060Ub92G8kN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 정규표현식 사용 --> 헤드라인 전처리, 단어 이외의 문자들은 띄어쓰기로 변경\n",
        "news_data['title'] = news_data['title'].str.replace(\"[^\\w]\", \" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh2Y6YkZiyU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "news_data['tag']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uxnlK40GaNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "news_data['tag_1'] = ''\n",
        "\n",
        "\n",
        "for i in range(len(news_data['tag'])) :\n",
        "  news_data['tag_1'][i]= news_data['tag'][i].replace(',',' ')\n",
        "\n",
        "  # .replace(',',' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjSInQPRa22i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "news_data['headline']=news_data['title'] +' ' + news_data['tag_1']\n",
        "news_data['headline']\n",
        "news_data['category'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2frf1Kn8G9gC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split하면서 shuffle 적용\n",
        "news_train, news_test, y_train, y_test = train_test_split(news_data['headline'], news_data['category'], test_size=0.2,shuffle=True, stratify=news_data['category'])\n",
        "\n",
        "# 원핫벡터로 만들어줍시다! (num_classes로 카테고리 수 명시 가능)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "print(len(y_train[0]))\n",
        "print(len(y_test[0]))\n",
        "\n",
        "# y_train.nunique(), y_test.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v48pgHo2gNRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egb0SZf0G-3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 토큰화 진행 --> a나 an 제거, 띄어쓰기 기준으로 문장 잘라 list에 담기 - X_train, X_test 둘 다 해줘야함!\n",
        "stopwords = ['또', 'an']\n",
        "\n",
        "X_train = []\n",
        "for stc in news_train:\n",
        "    token = []\n",
        "    words = stc.split()\n",
        "    for word in words:\n",
        "        if word not in stopwords:\n",
        "            token.append(word)\n",
        "    X_train.append(token)\n",
        "\n",
        "X_test = []\n",
        "for stc in news_test:\n",
        "    token = []\n",
        "    words = stc.split()\n",
        "    for word in words:\n",
        "        if word not in stopwords:\n",
        "            token.append(word)\n",
        "    X_test.append(token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwR3ugxKoVdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2TdBHcwHA7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# 헤드라인 정수인코딩\n",
        "tokenizer = Tokenizer(1000) #빈도수\n",
        "tokenizer.fit_on_texts(X_train) #vocabulary 만들기\n",
        "X_train = tokenizer.texts_to_sequences(X_train) # vocabulary랑 매칭해 인덱스로 나타내기\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq1QqXLFsRZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_train)\n",
        "print(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBKVMIAPHCXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(tokenizer.word_index)) #  단어가 2번 이하로 나온 것들 26916개. 2번 이상 나온 것들 약 25000으로 잡고 25000 토크나이저\n",
        "\n",
        "wc = 0\n",
        "for word, word_count in tokenizer.word_counts.items():\n",
        "    if word_count <= 2:\n",
        "        wc += 1\n",
        "\n",
        "print(wc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdmyLiGHHEUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt # 제목에 20단어가 넘는 건 거의 없음\n",
        "\n",
        "len_stc = []\n",
        "for data in X_train:\n",
        "    len_stc.append(len(data))\n",
        "\n",
        "y, x, _ = plt.hist(len_stc, bins=100)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FlbIpERHFuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 20 # 헤드라인 문장 길이를 보고 맞춰주기 - 패딩\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)\n",
        "\n",
        "# y_train.nunique()\n",
        "# y_test.nunique()\n",
        "X_test\n",
        "# X_train, X_test\n",
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgB8_3_DHG6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(1000, 128))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(24, activation='softmax')) #출력개수 24개의 카테고리"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loIwsdJhHIKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=30, epochs=10)\n",
        "\n",
        "#batch_size : 한번의 batch마다 주는 데이터 샘플 사이즈/ 한 번에 모든 데이터를 넣을 수가 없음\n",
        "#iteration \n",
        "# epoch : 전체 데이터 셋에 대해 한 번 학습을 완료한 상태"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdsCQWOQHJb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = input()\n",
        "token_stc = sentence.split()\n",
        "encode_stc = tokenizer.texts_to_sequences([token_stc])\n",
        "pad_stc = pad_sequences(encode_stc, maxlen=15)\n",
        "\n",
        "score = model.predict(pad_stc)\n",
        "print(category_list[score.argmax()], score[0, score.argmax()]) # 확률값 반환"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaulerIFohtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}